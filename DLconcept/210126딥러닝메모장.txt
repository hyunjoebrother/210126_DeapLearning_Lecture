210126 모두를 위한 딥런이 강좌 시즌

개념 공부 ON -> 익히고 LSTM 도전 -> 활동 보고서 ppt 작성 + GitHiub 업로드

#### Lec 00 - ML/DL 수업 개요와 일정

복잡한 많은 data에서 의사결정을 해야할 때
머신러닝 (Machine Learnin, ML)을 이용해서 정확하고 빠르게 하자 -> "super power"

* 강의 목표 : ML 알고리즘 이해 + Linear/Logistic regression (Deep Learning 이해)
	+ Tensorflow & Python으로 문제 해결

* Andrew Ng's ML class 참고

* 강의 일정 : 개념 -> Linear/Logistic Regression
	-> Multivariable (Vector) Regression -> Neural networks -> Deep Learning


#### Lect 01 - 기본적인 ML의 용어와 개념 설정

## ML
: 일종의 sw program -> 너무 많은 rule들로 인하여 하나하나 개발 어려움 (ex. 스팸 판별, 자율주행)

-> 개발자가 일일이 프로그래밍 하지 말고, 데이터를 '자동적'으로 배우는 것은 어떨까?

## Supervised / Unsupervised Learning
: Supervised
	-> 어떤 정해진 labeled 데이터 examples : "training set" -> 이 data로 학습
	ex) 여러 이미지들을 학습 (Image Lableling)
: Unsupervised
	-> un-labeled data 미리 label 주지 않고 data 보고 스스로 grouping 학습

-> 주로 Supervised Learning 사용 >> 학습하는 Data가 필요!

## training data set = X&Y
: 답(label)이 정해진 데이터 Y 를 통해서 데이터 X를 '학습'시킨다
-> ML이라는 model이 발생
-> 발생한 X_test 값이 나오면 model에 물어보면 값 Y가 나온다

ex) AlphaGo
: 알파고에 바둑판을 학습
-> 이세돌이 바둑을 넣은 걸 model에 입력 -> 바둑 위치값 나옴


## Types of Supervised Learing
* Predicting final exam score based on time spent
-> 값이 0~100 -> 범위가 넓은 것을 예측 : Regression

ex) 시험점수 training data -> ML model : Regression model
-> 이 학습 data로 training한다 -> 학습 기반으로 예측


* Not Score, by P/F(non-pass) based on time spent
-> Pass/Fail 중 하나를 고른다 -> 분류 : binary Classification

ex) P/F -> Classification -> Pass or Fail이니까 Binary

* Letter grade based on time spent
-> 학점에 따라 여러 label 중 하나를 고른다 -> 분류 : multi-based Classification

ex) A/B/C/D/F -> Classification -> Pass or Fail이니까 Multi-based


210127 모두를 위한 딥런이 강좌 시즌

#### Lab 01 - TensorFlow의 설치 및 기본적인 operations

## TensorFlow 
: Google에서 만든 오픈소스 library -> by Python
"data flow graph"를 사용해서 어떤 numerical 계산 computation

## Data Flow Graph(Node + Edge)
: Node (operation) + Edge (data array = tensor)
-> 계산이 일어나서 원하는 결과를 얻음 -> 이걸 하는 것이 tensorflow

$pip install --upgrade tensorflow 로 설치

Hello Tensorflow! 출력

## Computational Graph를 만들어보자

ex) Node A와 B가 plus로 연결 
그냥 연산하면 Tensor가 나오기 때문에
Session을 만들어서 run으로 graph를 실행시킨다

## TensorFlow Machanics

step1) TF를 이용하여 graph build
step2) sess.run으로 graph operation 실행
step3) 그 결과로 graph속 어떤 결과값 return


## Placeholder
: graph 실행시키는 단계에서 값 주고 싶을 때 (아까는 값이 먼저 주어짐)
-> Node를 만들 때 Placeholder라는 특별한 node로 만든다

: sess.run(op, feed_dict = {x: x_data})으로 graph 실행


## Tensor
- Rank
: 차원 (scalar (rank 0), vector (rank 1), matrix (rank 2), 3-Tensor (rank 3)...)

- Shape
: 각 element 갯수 -> [], [D0], [D0, D1]....
ex) t = {[1,2], [3,4], [5,6]} -> [3 (외부), 2 (내부)]

- Type
: tf.float32, int32 .....


210128 모두를 위한 딥런이 강좌 시즌

#### Lec 02 - Linear Regression의 Hypothesis와 cost 설명

* Predicting exam score : 0~100 범위 -> "Regression" model
x를 넣어서 y를 예측하자

* data
x : 예측을 하기 위한 기본적인 자료, feature
y : 예측할 값
-> x와 y : training data set

* Hypothesis 가설 
: 어떤 data가 linear한 것다 -> linear한 값을 찾는다
-> H(x) = Wx + b 일차 방정식 형태가 될 것이라는 '가설'을 세운다
-> W와 b 값에 따라서 linear한 선이 달라진다

* Which hypothesis is better?
: 실제 data와 H(x) 가설의 선과 가까우면 좋다! -> 그 거리 측정해보자

## Cost(loss) function
: 실제 data와 H(x) 사이의 거리 측정
-> ( H(x) - y )^2 값으로 check (부호 상관없도록 제곱)

* 모든 제곱값에 대한 평균, 일반화 = cost(W,b) 로 표현한다

* 목표 : cost값이 가장 작은minimize W와 b 값을 구해서 training하자


210129 모두를 위한 딥런이 강좌 시즌

#### Lab 02 - TensorFlow로 간단한 Linear Regression을 구현

## Hypothesis and Cost function

주어진 x에 대해서 예측을 어떻게 할 것인가
* 가설 H(x) = Wx + b
* 예측 cost(W,b) -> 실제 true 값 y 사용 -> cost를 minimize하자

## TensorFlow Machanics

step1) TF를 이용하여 graph build
step2) sess.run(op, feed_dict = {x:x_data}) 으로 graph operation 실행
step3) 그 결과로 graph속 어떤 결과값 return




















